{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:05:32.183140Z",
     "start_time": "2024-04-26T06:05:30.108458Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import nltk\n",
    "from torch.utils.data import Dataset\n",
    "import pickle\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.label_decoding import *\n",
    "from utils.HierarchicalLoss import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SubTask 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e60ad07d99dbae78"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, df, labels_at_level, features_file):\n",
    "        super(DataSet, self).__init__()\n",
    "        self.data_df = df\n",
    "        self.labels_at_level = labels_at_level\n",
    "        self.features_file = features_file\n",
    "        self.features_dict = None\n",
    "        with open(features_file, 'rb') as f:\n",
    "            self.features_dict = pickle.load(f)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        id = self.data_df.iloc[idx]['id']\n",
    "        text = self.data_df.iloc[idx]['cleaned_text']\n",
    "        level_1_target = self.encode(self.data_df.iloc[idx]['Level 1'], 1)\n",
    "        level_2_target = self.encode(self.data_df.iloc[idx]['Level 2'], 2)\n",
    "        level_3_target = self.encode(self.data_df.iloc[idx]['Level 3'], 3)\n",
    "        level_4_target = self.encode(self.data_df.iloc[idx]['Level 4'], 4)\n",
    "        level_5_target = self.encode(self.data_df.iloc[idx]['Level 5'], 5)\n",
    "            \n",
    "        \n",
    "        return {'id': id,\n",
    "                'text': text, \n",
    "                'text_features': self.features_dict[id],\n",
    "                'level_1_target': level_1_target, \n",
    "                'level_2_target': level_2_target, \n",
    "                'level_3_target': level_3_target, \n",
    "                'level_4_target': level_4_target, \n",
    "                'level_5_target': level_5_target }\n",
    "\n",
    "    def encode(self, labels, level):\n",
    "        level_ = f'Level {level}'\n",
    "        \n",
    "        target = torch.zeros(len(self.labels_at_level[level_])+1)\n",
    "        \n",
    "        for label in labels:\n",
    "            label_idx = self.labels_at_level[level_][label]\n",
    "            target[label_idx] = 1\n",
    "        \n",
    "        if len(labels) == 0:\n",
    "            target[-1] = 1\n",
    "        \n",
    "        return target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:05:33.662324Z",
     "start_time": "2024-04-26T06:05:33.656990Z"
    }
   },
   "id": "ca9a0fc432e64d68",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TestDataSet(Dataset):\n",
    "    def __init__(self, df, features_file):\n",
    "        super(TestDataSet, self).__init__()\n",
    "        self.data_df = df\n",
    "        self.features_file = features_file\n",
    "        self.features_dict = None\n",
    "        with open(features_file, 'rb') as f:\n",
    "            self.features_dict = pickle.load(f)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        id = self.data_df.iloc[idx]['id']\n",
    "        text = self.data_df.iloc[idx]['cleaned_text']\n",
    "        \n",
    "        return {'id': id,\n",
    "                'text': text, \n",
    "                'text_features': self.features_dict[id] }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:05:35.299993Z",
     "start_time": "2024-04-26T06:05:35.296986Z"
    }
   },
   "id": "6eac351a60082cf4",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, pred_file_path, gold_file_path, \n",
    "                   evaluator_script_path, id2leaf_label, format=None,validation=False, threshold=0.3):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    HL = HierarchicalLoss(id2label=id2label_1, hierarchical_labels=hierarchy_1, persuasion_techniques=persuasion_techniques_1, device=device)\n",
    "    total_loss = 0\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in tqdm(dataloader):\n",
    "            if not isinstance(batch['id'], list):\n",
    "                ids = batch['id'].detach().numpy().tolist()\n",
    "            else:\n",
    "                ids = batch['id']\n",
    "        \n",
    "            embeddings = batch['text_features']\n",
    "            embeddings = embeddings.to(device)\n",
    "            pred_1, pred_2, pred_3, pred_4, pred_5 = model(embeddings)\n",
    "            \n",
    "            if validation:\n",
    "                y_1, y_2, y_3 = batch['level_1_target'], batch['level_2_target'], batch['level_3_target']\n",
    "                y_4, y_5 = batch['level_4_target'], batch['level_5_target']\n",
    "                \n",
    "                y_1, y_2, y_3, y_4, y_5 = y_1.to(device), y_2.to(device), y_3.to(device), y_4.to(device), y_5.to(device)\n",
    "                \n",
    "                dloss = HL.calculate_dloss([pred_1, pred_2, pred_3, pred_4, pred_5], [y_1, y_2, y_3, y_4, y_5])\n",
    "                lloss = HL.calculate_lloss([pred_1, pred_2, pred_3, pred_4, pred_5], [y_1, y_2, y_3, y_4, y_5])\n",
    "                \n",
    "                total_loss += (dloss + lloss).detach().cpu().item()\n",
    "                \n",
    "            pred_3 = (pred_3.cpu().detach().numpy() > threshold).astype(int)\n",
    "            pred_4 = (pred_4.cpu().detach().numpy() > threshold).astype(int)\n",
    "            pred_5 = (pred_5.cpu().detach().numpy() > threshold).astype(int)\n",
    "            \n",
    "            predictions += get_labels(id2leaf_label, ids, pred_3, pred_4, pred_5, format)\n",
    "\n",
    "        # Writing JSON data\n",
    "        with open(pred_file_path, 'w') as f:\n",
    "            json.dump(predictions, f, indent=4)\n",
    "        \n",
    "        if gold_file_path is None:\n",
    "            return\n",
    "            \n",
    "        command = [\n",
    "                \"python3\", evaluator_script_path,\n",
    "                \"--gold_file_path\", gold_file_path,\n",
    "                \"--pred_file_path\", pred_file_path\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"Output:\\n\", result.stdout)\n",
    "        else:\n",
    "            print(\"Error:\\n\", result.stderr)\n",
    "            \n",
    "        if validation:\n",
    "            return total_loss / len(dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:05:38.521581Z",
     "start_time": "2024-04-26T06:05:38.515593Z"
    }
   },
   "id": "ec033c418f6dd4da",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = process_json('./semeval2024_dev_release/subtask1/train.json', techniques_to_level_1, hierarchy_1)\n",
    "# val_data = \n",
    "validation_data = process_json('./semeval2024_dev_release/subtask1/validation.json', techniques_to_level_1, hierarchy_1)\n",
    "\n",
    "training_dataset = DataSet(train_data, indexed_persuasion_techniques_1, \n",
    "                           './TextFeatures/subtask1a/text-embedding-3-large/train_text_features.pkl')\n",
    "validation_dataset = DataSet(validation_data, indexed_persuasion_techniques_1, \n",
    "                             './TextFeatures/subtask1a/text-embedding-3-large/validation_text_features.pkl')\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:05:40.790224Z",
     "start_time": "2024-04-26T06:05:40.040487Z"
    }
   },
   "id": "ad284fce512b8868",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "alpha = 0.7764469620072395\n",
    "batch_size = 256\n",
    "beta = 0.95\n",
    "beta1 = 0.9094170903394552\n",
    "learning_rate = 3.906930058023181e-05\n",
    "threshold = 0.8256232754296409"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:05:41.470194Z",
     "start_time": "2024-04-26T06:05:41.468113Z"
    }
   },
   "id": "859b0a5dc9196624",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "device = get_device()\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "HL = HierarchicalLoss(id2label=id2label_1, hierarchical_labels=hierarchy_1,\n",
    "                      persuasion_techniques=persuasion_techniques_1,\n",
    "                      device=device, alpha=alpha, beta=beta, threshold=threshold)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:05:45.839765Z",
     "start_time": "2024-04-26T06:05:45.819552Z"
    }
   },
   "id": "20d17410814334b2",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d73018686502c960"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "OpenAiLarge(\n  (linear_level1): Sequential(\n    (0): Linear(in_features=3072, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.15, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.15, inplace=False)\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): ReLU()\n  )\n  (linear_level2): Sequential(\n    (0): Linear(in_features=3072, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.15, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.15, inplace=False)\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): ReLU()\n  )\n  (linear_level3): Sequential(\n    (0): Linear(in_features=3072, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.15, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.15, inplace=False)\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): ReLU()\n  )\n  (linear_level4): Sequential(\n    (0): Linear(in_features=3072, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.15, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.15, inplace=False)\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): ReLU()\n  )\n  (linear_level5): Sequential(\n    (0): Linear(in_features=3072, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.15, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.15, inplace=False)\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): ReLU()\n  )\n  (sigmoid_reg1): Sequential(\n    (0): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (sigmoid_reg2): Sequential(\n    (0): Linear(in_features=256, out_features=4, bias=True)\n  )\n  (sigmoid_reg3): Sequential(\n    (0): Linear(in_features=384, out_features=13, bias=True)\n    (1): Sigmoid()\n  )\n  (sigmoid_reg4): Sequential(\n    (0): Linear(in_features=512, out_features=13, bias=True)\n    (1): Sigmoid()\n  )\n  (sigmoid_reg5): Sequential(\n    (0): Linear(in_features=640, out_features=7, bias=True)\n    (1): Sigmoid()\n  )\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.nn.OpenAiLarge import OpenAiLarge\n",
    "\n",
    "model = OpenAiLarge()\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:05:57.151918Z",
     "start_time": "2024-04-26T06:05:57.076983Z"
    }
   },
   "id": "30ec7416987a643",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 20] loss: 2515.505\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 45\u001B[0m\n\u001B[1;32m     42\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m lloss \u001B[38;5;241m+\u001B[39m dloss\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# loss_.backward()\u001B[39;00m\n\u001B[0;32m---> 45\u001B[0m \u001B[43mtotal_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     48\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m total_loss\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/Desktop/Python Assignments/venv/lib/python3.11/site-packages/torch/_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    491\u001B[0m     )\n\u001B[0;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Python Assignments/venv/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0004306099142228309, betas=(0.8923286832300139, 0.999))\n",
    "min_val_loss = float('inf')\n",
    "best_epoch = None\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        # input_ids, masks, type_ids  = batch['input_ids'], batch['attention_mask'], batch['token_type_ids']\n",
    "        # encoded_inputs = batch['encoded_input']\n",
    "        # input_ids, masks = encoded_inputs['input_ids'], encoded_inputs['attention_mask'], \n",
    "        # type_ids = encoded_inputs['token_type_ids']\n",
    "        y_1, y_2, y_3 = batch['level_1_target'], batch['level_2_target'], batch['level_3_target']\n",
    "        y_4, y_5 = batch['level_4_target'], batch['level_5_target']\n",
    "        \n",
    "        # input_ids = input_ids.squeeze().to(device)\n",
    "        # masks = masks.squeeze().to(device)\n",
    "        # type_ids = type_ids.squeeze().to(device)\n",
    "        # encoded_inputs = encoded_inputs.to(device)\n",
    "        \n",
    "        # print(type(batch['text_features']))\n",
    "        \n",
    "        embeddings = batch['text_features']\n",
    "        embeddings = embeddings.to(device)\n",
    "        y_1, y_2, y_3, y_4, y_5 = y_1.to(device), y_2.to(device), y_3.to(device), y_4.to(device), y_5.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred_1, pred_2, pred_3, pred_4, pred_5 = model(embeddings)\n",
    "        # loss_ = loss(pred_1, y_1) + loss(pred_2, y_2) + loss(pred_3, y_3) + loss(pred_4, y_4) + loss(pred_5, y_5)\n",
    "        \n",
    "        dloss = HL.calculate_dloss([pred_1, pred_2, pred_3, pred_4, pred_5], [y_1, y_2, y_3, y_4, y_5])\n",
    "        lloss = HL.calculate_lloss([pred_1, pred_2, pred_3, pred_4, pred_5], [y_1, y_2, y_3, y_4, y_5])\n",
    "\n",
    "        total_loss = lloss + dloss\n",
    "        # loss_.backward()\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += total_loss.detach().item()\n",
    "        \n",
    "        if batch_idx % 20 == 19:\n",
    "            print(f\"[{epoch + 1}, {batch_idx + 1}] loss: {running_loss / 20:.3f}\")\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    running_loss /= len(train_dataloader)\n",
    "    \n",
    "    val_pred_file_path = './Predictions/val_predictions_subtask1.json'\n",
    "    val_gold_file_path = './semeval2024_dev_release/subtask1/validation.json'\n",
    "    evaluator_script = './scorer-baseline/subtask_1_2a.py'\n",
    "    \n",
    "    validation_loss = evaluate_model(model, validation_dataloader, val_pred_file_path, \n",
    "                                     val_gold_file_path, evaluator_script,id2leaf_label,\n",
    "                                     validation=True)\n",
    "    \n",
    "    train_loss_history.append(running_loss)\n",
    "    val_loss_history.append(validation_loss)\n",
    "    \n",
    "    if validation_loss < min_val_loss:\n",
    "        min_val_loss = validation_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), './models/best_subtask1_baseline.pth')\n",
    "\n",
    "print(f'best validation loss occurred in epoch {best_epoch} ')\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:06:01.490709Z",
     "start_time": "2024-04-26T06:05:57.855158Z"
    }
   },
   "id": "d5df83d5c933d40e",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/subtask1a/text-embedding-3-small/openai_small-3.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T21:32:20.137837Z",
     "start_time": "2024-04-24T21:32:20.044075Z"
    }
   },
   "id": "3770a01eb7577588",
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./models/best_subtask1_baseline.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T02:19:19.211593Z",
     "start_time": "2024-03-31T02:19:19.139110Z"
    }
   },
   "id": "94833d43b91e208f",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "OpenAiLarge(\n  (linear_level1): Sequential(\n    (0): Linear(in_features=3072, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.15, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.15, inplace=False)\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): ReLU()\n  )\n  (linear_level2): Sequential(\n    (0): Linear(in_features=3072, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.15, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.15, inplace=False)\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): ReLU()\n  )\n  (linear_level3): Sequential(\n    (0): Linear(in_features=3072, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.15, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.15, inplace=False)\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): ReLU()\n  )\n  (linear_level4): Sequential(\n    (0): Linear(in_features=3072, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.15, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.15, inplace=False)\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): ReLU()\n  )\n  (linear_level5): Sequential(\n    (0): Linear(in_features=3072, out_features=1024, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.15, inplace=False)\n    (3): Linear(in_features=1024, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.15, inplace=False)\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): ReLU()\n  )\n  (sigmoid_reg1): Sequential(\n    (0): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (sigmoid_reg2): Sequential(\n    (0): Linear(in_features=256, out_features=4, bias=True)\n  )\n  (sigmoid_reg3): Sequential(\n    (0): Linear(in_features=384, out_features=13, bias=True)\n    (1): Sigmoid()\n  )\n  (sigmoid_reg4): Sequential(\n    (0): Linear(in_features=512, out_features=13, bias=True)\n    (1): Sigmoid()\n  )\n  (sigmoid_reg5): Sequential(\n    (0): Linear(in_features=640, out_features=7, bias=True)\n    (1): Sigmoid()\n  )\n)"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OpenAiLarge()\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T22:11:45.296268Z",
     "start_time": "2024-04-24T22:11:45.221126Z"
    }
   },
   "id": "e48019726f1020af",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./models/subtask1a/openAI-Large/giddy-sweep-11.pth', map_location=device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:06:08.402455Z",
     "start_time": "2024-04-26T06:06:08.382618Z"
    }
   },
   "id": "8243fca7b14d4540",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "451ffa2b1dd6efcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bulgarian"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e28d86721d601ea"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 115.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " f1_h=0.41630\tprec_h=0.46651\trec_h=0.37584\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "bulgarian_pred_file_path = './Predictions/bulgarian_predictions_subtask1.txt'\n",
    "bulgarian_gold_file_path = './test_labels_ar_bg_md_version2/test_subtask1_bg.json'\n",
    "evaluator_script = './scorer-baseline/subtask_1_2a.py'\n",
    "\n",
    "bg_test_data = process_test_json(bulgarian_gold_file_path)\n",
    "\n",
    "\n",
    "bg_test_dataset = TestDataSet(bg_test_data, './TextFeatures/subtask1a/text-embedding-3-large/bg_test_text_features.pkl')\n",
    "bg_test_dataloader = DataLoader(bg_test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "evaluate_model(model, bg_test_dataloader, bulgarian_pred_file_path, bulgarian_gold_file_path,\n",
    "               evaluator_script, id2leaf_label, validation=False, threshold=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:06:14.358255Z",
     "start_time": "2024-04-26T06:06:13.534589Z"
    }
   },
   "id": "4ea39e7341d42058",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " f1_h=0.93627\tprec_h=0.99888\trec_h=0.88105\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, train_dataloader, 'train_pred.json', 'semeval2024_dev_release/subtask1/train.json',\n",
    "               evaluator_script, id2leaf_label, validation=False, threshold=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:06:18.244299Z",
     "start_time": "2024-04-26T06:06:15.726294Z"
    }
   },
   "id": "b4c77e04f4d2acf5",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " f1_h=0.57012\tprec_h=0.62277\trec_h=0.52569\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, validation_dataloader, 'valid_pred.json', 'semeval2024_dev_release/subtask1/validation.json',\n",
    "               evaluator_script, id2leaf_label, validation=False, threshold=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:06:20.311492Z",
     "start_time": "2024-04-26T06:06:19.352660Z"
    }
   },
   "id": "59b5cc2847c84fbe",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### North Macedonian"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6449d039338dd725"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 116.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " f1_h=0.36864\tprec_h=0.57254\trec_h=0.27183\n"
     ]
    }
   ],
   "source": [
    "macedonian_pred_file_path = './Predictions/macedonian_predictions_subtask1.txt'\n",
    "macedonian_gold_file_path = './test_labels_ar_bg_md_version2/test_subtask1_md.json'\n",
    "\n",
    "md_test_data = process_test_json(macedonian_gold_file_path)\n",
    "\n",
    "md_test_dataset = TestDataSet(md_test_data, './TextFeatures/subtask1a/text-embedding-3-large/md_test_text_features.pkl')\n",
    "md_test_dataloader = DataLoader(md_test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "evaluate_model(model, md_test_dataloader, macedonian_pred_file_path, macedonian_gold_file_path,\n",
    "               evaluator_script, id2leaf_label, validation=False, threshold=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:06:22.087426Z",
     "start_time": "2024-04-26T06:06:21.384793Z"
    }
   },
   "id": "cc2bfd0a1c8c0be6",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Arabian"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d40e62c0b95c12c9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 59.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " f1_h=0.35110\tprec_h=0.31728\trec_h=0.39298\n"
     ]
    }
   ],
   "source": [
    "arabian_pred_file_path = './Predictions/arabian_predictions_subtask1.txt'\n",
    "arabian_gold_file_path = './test_labels_ar_bg_md_version2/test_subtask1_ar.json'\n",
    "\n",
    "ar_test_data = process_test_json(arabian_gold_file_path)\n",
    "\n",
    "ar_test_dataset = TestDataSet(ar_test_data, './TextFeatures/subtask1a/text-embedding-3-large/ar_test_text_features.pkl')\n",
    "ar_test_dataloader = DataLoader(ar_test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "evaluate_model(model, ar_test_dataloader, arabian_pred_file_path, arabian_gold_file_path, evaluator_script, \n",
    "               id2leaf_label, format=5, validation=False, threshold=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:06:24.385775Z",
     "start_time": "2024-04-26T06:06:23.694053Z"
    }
   },
   "id": "c9290f37d694f195",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### English"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a48eeae07b80b484"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:01<00:00, 83.32it/s] \n"
     ]
    }
   ],
   "source": [
    "en_pred_file_path = './Predictions/en_predictions_subtask1.txt'\n",
    "\n",
    "en_test_data = process_test_json('./test_data/english/en_subtask1_test_unlabeled.json')\n",
    "\n",
    "en_test_dataset = TestDataSet(en_test_data, './TextFeatures/subtask1a/text-embedding-3-large/en_test_text_features.pkl')\n",
    "en_test_dataloader = DataLoader(en_test_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "evaluate_model(model, en_test_dataloader, en_pred_file_path, None, evaluator_script, id2leaf_label, validation=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:06:47.246278Z",
     "start_time": "2024-04-26T06:06:46.075305Z"
    }
   },
   "id": "38e92cd24285bce6",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'id': '74963',\n  'labels': ['Black-and-white Fallacy/Dictatorship', 'Appeal to authority']},\n {'id': '64968', 'labels': ['Loaded Language']},\n {'id': '68517', 'labels': ['Name calling/Labeling']},\n {'id': '68199', 'labels': []},\n {'id': '77926', 'labels': []},\n {'id': '77339', 'labels': ['Causal Oversimplification']},\n {'id': '67938', 'labels': ['Black-and-white Fallacy/Dictatorship']},\n {'id': '75036', 'labels': ['Smears', 'Thought-terminating cliché']},\n {'id': '65794', 'labels': []},\n {'id': '76075',\n  'labels': ['Smears', 'Appeal to authority', 'Name calling/Labeling']},\n {'id': '65649', 'labels': ['Smears']},\n {'id': '76963', 'labels': ['Causal Oversimplification']},\n {'id': '68530', 'labels': ['Doubt']},\n {'id': '65374',\n  'labels': ['Name calling/Labeling', 'Smears', 'Loaded Language']},\n {'id': '64551', 'labels': []},\n {'id': '79789', 'labels': ['Smears']}]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iterator = iter(en_test_dataloader)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batch = next(data_iterator)\n",
    "    pred_1, pred_2, pred_3, pred_4, pred_5 = model(batch['text_features'])\n",
    "\n",
    "t = 0.7\n",
    "    \n",
    "pred_3 = (pred_3.cpu().detach().numpy() > t).astype(int)\n",
    "pred_4 = (pred_4.cpu().detach().numpy() > t).astype(int)\n",
    "pred_5 = (pred_5.cpu().detach().numpy() > t).astype(int)\n",
    "            \n",
    "get_labels(id2leaf_label, batch['id'].tolist(), pred_3, pred_4, pred_5, format=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T06:06:56.775228Z",
     "start_time": "2024-04-26T06:06:56.761068Z"
    }
   },
   "id": "837c7c51332ba1f3",
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
